# D√©tection de la Sant√© Mentale √† partir des R√©seaux Sociaux en utilisant NLP

Ce projet acad√©mique vise √† exploiter les techniques de **Traitement Automatique du Langage Naturel (NLP)** afin de d√©tecter automatiquement diff√©rents √©tats de sant√© mentale √† partir de publications issues des r√©seaux sociaux.

Il est r√©alis√© dans le cadre de la fili√®re **Big Data & Intelligence Artificielle (BDIA)**  
**ENSA T√©touan ‚Äì Ann√©e universitaire 2025‚Äì2026**

**Avertissement** : Ce travail est strictement acad√©mique et exp√©rimental.  
Il ne constitue en aucun cas un outil de diagnostic m√©dical.

---

## Objectifs du projet

- Analyser des donn√©es textuelles issues des r√©seaux sociaux (principalement Reddit)
- D√©tecter automatiquement plusieurs √©tats de sant√© mentale (classification multi-classes)
- Comparer des approches classiques et avanc√©es en NLP :
  - **TF-IDF + SVM lin√©aire calibr√©**
  - **BERT**
  - **RoBERTa**
- √âvaluer les performances avec des m√©triques adapt√©es aux donn√©es d√©s√©quilibr√©es
- D√©ployer une application interactive pour comparer les pr√©dictions des mod√®les

---

## Probl√©matique abord√©e

La sant√© mentale regroupe des √©tats vari√©s, souvent exprim√©s de mani√®re implicite dans le langage naturel.
L‚Äôobjectif est d‚Äôidentifier automatiquement ces √©tats √† partir de textes courts, bruit√©s et subjectifs, ce qui repr√©sente un d√©fi majeur en NLP. Le probl√®me est formul√© comme une t√¢che de classification multi-classes √† 14 cat√©gories.

## √âtats de sant√© mentale √©tudi√©s

Le probl√®me est formul√© comme une t√¢che de **classification multi-classes** couvrant 14 √©tats :

- Depression  
- Suicidal  
- ADHD  
- Bipolar disorder  
- Normal  
- OCD  
- PTSD  
- Anxiety  
- Stress  
- Personality disorder  
- Aspergers  
- Schizophrenia  
- Addiction  
- Alcoholism  

---

## M√©thodologie g√©n√©rale

La m√©thodologie suivie dans ce projet repose sur les √©tapes suivantes :

* Collecte et pr√©paration des donn√©es

* Pr√©traitement linguistique des textes

* Repr√©sentation vectorielle

* Entra√Ænement de mod√®les de classification

* √âvaluation sur des m√©triques adapt√©es

* Comparaison des approches

* D√©ploiement d‚Äôune interface interactive

## Mod√®les impl√©ment√©s

### üîπ TF-IDF + SVM lin√©aire (Baseline)
- Vectorisation TF-IDF (unigrammes + bigrammes)
- Vocabulaire limit√© √† 50 000 termes
- Pond√©ration automatique des classes
- Calibration des probabilit√©s (Platt Scaling)
- Mod√®le rapide, interpr√©table et robuste

### üîπ BERT (Fine-tuning supervis√©)
- Tokenisation WordPiece
- Repr√©sentations contextuelles bidirectionnelles
- Pond√©ration des classes dans la fonction de perte
- Dropout, gradient clipping et early stopping
- Tr√®s bonne d√©tection des classes minoritaires

### üîπ RoBERTa
- Suppression de la t√¢che NSP
- Masquage dynamique
- Pr√©-entra√Ænement optimis√©
- Fine-tuning supervis√© avec r√©gularisation
- Performances globales tr√®s √©lev√©es et stables

---

## R√©sultats exp√©rimentaux des mod√®les

Les mod√®les ont √©t√© √©valu√©s √† l‚Äôaide de m√©triques adapt√©es aux jeux de donn√©es d√©s√©quilibr√©s :  
**Accuracy**, **F1-score Macro** et **F1-score Weighted**.

###  R√©sultats globaux

| Mod√®le                   | Accuracy | F1-score (Macro) | F1-score (Weighted) |
|--------------------------|----------|------------------|---------------------|
| TF-IDF + SVM (baseline) | 0.7647   | 0.7889           | 0.7650              |
| BERT                    | 0.8176   | 0.8429           | 0.8185              |
| RoBERTa                 | 0.8100   | 0.8400           | 0.8100              |

###  Analyse

- Les mod√®les **Transformers (BERT et RoBERTa)** surpassent largement la baseline TF-IDF + SVM  
- **BERT obtient les meilleures performances globales**, notamment en F1-score Macro  
- **RoBERTa reste tr√®s comp√©titif**, avec des performances proches et une grande stabilit√©  
- Le **F1-score Macro** confirme une meilleure prise en compte des classes minoritaires, ce qui est crucial en sant√© mentale  

---

## Perspectives et am√©liorations futures

* Comment r√©duire efficacement les confusions entre √©tats de sant√© mentale proches (ex. anxiety vs stress, depression vs suicidal) alors que leurs expressions linguistiques se recouvrent fortement sur les r√©seaux sociaux ?
* Faut-il privil√©gier des approches hi√©rarchiques, multi-labels ou contextuelles pour mieux capturer cette complexit√© s√©mantique ?
* Dans quelle mesure l‚Äôint√©gration de donn√©es temporelles, d‚Äôannotations expertes ou de mod√®les sp√©cialis√©s pourrait-elle am√©liorer la distinction entre ces classes ?

Ces questions ouvrent la voie √† des travaux futurs et √† des collaborations interdisciplinaires entre NLP, psychologie et sciences sociales.

## Reproduction des r√©sultats 

Cette section d√©crit les √©tapes n√©cessaires pour reproduire les r√©sultats exp√©rimentaux pr√©sent√©s dans ce projet.

### Pr√©requis

- Python **3.9+**
- Environnement virtuel recommand√©
- Syst√®me d‚Äôexploitation : Windows / Linux / macOS
- GPU recommand√© pour l‚Äôentra√Ænement de BERT et RoBERTa (optionnel mais conseill√©)

---

### Installation de l‚Äôenvironnement

- Cloner le d√©p√¥t :
```bash
git clone https://github.com/itsmawna/Nlp-Mental-Health-Detection.git
cd NLP-Mental-Health-Detection
```
- Cr√©er et activer un environnement virtuel :
```bash
python -m venv venv
source venv/bin/activate      # Linux / macOS
venv\Scripts\activate         # Windows
```
- Installer les d√©pendances :
```bash
pip install -r requirements.txt
```
### Pr√©paration des donn√©es

Les jeux de donn√©es ne sont pas inclus dans le d√©p√¥t pour des raisons de **taille** et d‚Äô**√©thique**.

Les notebooks suivants permettent de reproduire l‚Äôensemble de la pr√©paration des donn√©es :

- `notebooks/dataextraction_from_hugging_face.ipynb`
- `notebooks/preprocessing.ipynb`
- `notebooks/preprocessing final.ipynb`

Les donn√©es pr√©trait√©es doivent √™tre plac√©es dans le dossier `data/`.

---

### Entra√Ænement des mod√®les

Chaque mod√®le peut √™tre reproduit √† l‚Äôaide de son notebook d√©di√© :

- **TF-IDF + SVM**
  - `notebooks/tf-idf-linear-svm-calibrated.ipynb`

- **BERT**
  - `notebooks/nlp-bert.ipynb`

- **RoBERTa**
  - `notebooks/roberta-mental-health.ipynb`

Les mod√®les entra√Æn√©s sont g√©n√©r√©s **localement** et sauvegard√©s dans le dossier `models/`  
(ce dossier est ignor√© par Git en raison de la taille des fichiers).

---

### √âvaluation des performances

Les notebooks incluent :
- Les m√©triques globales : **Accuracy**, **F1-score Macro**, **F1-score Weighted**
- Les rapports de classification d√©taill√©s par classe
- Les matrices de confusion
- La s√©lection du meilleur mod√®le selon le **F1-score Macro**

---

### Lancement de l‚Äôapplication

Une fois les mod√®les entra√Æn√©s, l‚Äôapplication Streamlit peut √™tre lanc√©e avec la commande suivante :

```bash
streamlit run app/streamlit_compare.py
```
L‚Äôinterface permet :
- La saisie de textes libres
- La comparaison des pr√©dictions des mod√®les
- L‚Äôaffichage des probabilit√©s associ√©es
- Une politique de d√©cision prudente

### Reproductibilit√©

- Les splits des donn√©es sont r√©alis√©s de mani√®re stratifi√©e
- Les graines al√©atoires sont fix√©es afin d‚Äôassurer la reproductibilit√©
- Les hyperparam√®tres finaux sont document√©s dans les notebooks
- Les performances peuvent varier l√©g√®rement selon le mat√©riel et la configuration logicielle.
---


## Consid√©rations √©thiques

- Les r√©sultats produits ne doivent **jamais √™tre interpr√©t√©s comme un diagnostic m√©dical**
- Le projet vise uniquement l‚Äôanalyse, la recherche et la d√©monstration acad√©mique
- Une attention particuli√®re est port√©e √† la gestion des biais et √† la protection de la vie priv√©e

---

<p align="center">
  <strong>Happy learning & coding ! üöÄü§ñüìö</strong>
</p>



